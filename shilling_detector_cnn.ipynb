{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Set-up code\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install sklearn\n",
        "!pip install openpyxl\n",
        "!pip install numpy\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "SHfTyAjN2XAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0dbfb4-0909-4c64-dfa1-05b6bebceb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.9/dist-packages (0.0.post1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (63.4.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIEBROHoWHkn"
      },
      "outputs": [],
      "source": [
        "from pandas.core.arrays import categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Embedding\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.metrics import Precision, Recall, BinaryAccuracy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "from scipy.stats import zscore\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "ratings = pd.read_csv('sample_data/amazon_50k.csv')\n",
        "empty_cols = [col for col in ratings.columns if ratings[col].isnull().all()]\n",
        "\n",
        "if len(empty_cols) > 0:\n",
        "    # Remove the empty column\n",
        "    ratings = ratings.drop(columns=empty_cols)\n",
        "\n",
        "ratings.columns = ['userId', 'itemId', 'rating']\n",
        "print(ratings)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_pb5tubWRiv",
        "outputId": "903a16b5-5980-42e8-f3c0-0d8b08fa278d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               userId      itemId  rating\n",
            "0      A2OXDRWBASV91Y  B00004SQHD       5\n",
            "1      A2KG6AWJSWILPR  B00004SQHD       5\n",
            "2      A2CBE6VYOARZN4  B00004SQHD       5\n",
            "3       AVKOTZD5ZIOX5  B00004SQHD       5\n",
            "4      A33DUVUIC7G553  B00004SQHD       5\n",
            "...               ...         ...     ...\n",
            "53764   A1JCY9IVF34DE  B000THKV4O       1\n",
            "53765  A3B834ZT5C1GCW  B000THKV4O       5\n",
            "53766  A23NSKTMSPPBTR  B000THKV4O       5\n",
            "53767  A2KP45DO3RY4RG  B000THKV4O       5\n",
            "53768   A9YKOX54Y35KL  B000THKV4O       5\n",
            "\n",
            "[53769 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a binary column indicating whether a rating is suspicious (1) or not (0)\n",
        "#ratings['suspicious'] = np.where(ratings['rating'] >= 4, 0, 1)\n",
        "#print(ratings)\n",
        "\n",
        "mean = np.mean(ratings['rating'])\n",
        "std = np.std(ratings['rating'])\n",
        "ratings['z-score'] = (ratings['rating'] - mean)/std\n",
        "\n",
        "threshold = 2.0\n",
        "ratings['sus'] = np.where(ratings['z-score'].abs() > threshold, 1, 0)\n",
        "print(ratings)\n",
        "\n",
        "\n",
        "user_encoder = preprocessing.LabelEncoder()\n",
        "user_encoder.fit(ratings['userId'])\n",
        "item_encoder = preprocessing.LabelEncoder()\n",
        "ratings['userId'] = user_encoder.transform(ratings['userId'])\n",
        "ratings['itemId'] = item_encoder.fit_transform(ratings['itemId'])\n",
        "print('------------------encoded user and item IDs---------------------')\n",
        "print(ratings)\n",
        "\n"
      ],
      "metadata": {
        "id": "vA0bUNaF7k28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c5a1b3-1347-4a9a-98b2-a190ddffb676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               userId      itemId  rating   z-score  sus\n",
            "0      A2OXDRWBASV91Y  B00004SQHD       5  0.595943    0\n",
            "1      A2KG6AWJSWILPR  B00004SQHD       5  0.595943    0\n",
            "2      A2CBE6VYOARZN4  B00004SQHD       5  0.595943    0\n",
            "3       AVKOTZD5ZIOX5  B00004SQHD       5  0.595943    0\n",
            "4      A33DUVUIC7G553  B00004SQHD       5  0.595943    0\n",
            "...               ...         ...     ...       ...  ...\n",
            "53764   A1JCY9IVF34DE  B000THKV4O       1 -2.641896    1\n",
            "53765  A3B834ZT5C1GCW  B000THKV4O       5  0.595943    0\n",
            "53766  A23NSKTMSPPBTR  B000THKV4O       5  0.595943    0\n",
            "53767  A2KP45DO3RY4RG  B000THKV4O       5  0.595943    0\n",
            "53768   A9YKOX54Y35KL  B000THKV4O       5  0.595943    0\n",
            "\n",
            "[53769 rows x 5 columns]\n",
            "------------------encoded user and item IDs---------------------\n",
            "       userId  itemId  rating   z-score  sus\n",
            "0       23244       0       5  0.595943    0\n",
            "1       21528       0       5  0.595943    0\n",
            "2       18428       0       5  0.595943    0\n",
            "3       50141       0       5  0.595943    0\n",
            "4       28730       0       5  0.595943    0\n",
            "...       ...     ...     ...       ...  ...\n",
            "53764    7404     413       1 -2.641896    1\n",
            "53765   31722     413       5  0.595943    0\n",
            "53766   15100     413       5  0.595943    0\n",
            "53767   21624     413       5  0.595943    0\n",
            "53768   42014     413       5  0.595943    0\n",
            "\n",
            "[53769 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the training and testing sets into arrays\n",
        "X_train = np.array(train['userId'])\n",
        "y_train = np.array(train['sus'])\n",
        "X_test = np.array(test['userId'])\n",
        "y_test = np.array(test['sus'])\n",
        "\n",
        "# Compute the number of unique user IDs in the dataset\n",
        "num_users = ratings['userId'].nunique()\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Reshape the input data to be a 3D tensor with shape (samples, time steps, features)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, 1))"
      ],
      "metadata": {
        "id": "GPFODBRoBAZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "3Yv8hS4boYJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.RootMeanSquaredError(), f1_m, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
        "\n",
        "#Make predictions on the train and test sets\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
        "y_test_pred = model.predict(X_test)\n",
        "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
        "\n",
        "#Generate true and predicted labels\n",
        "y_train_true = y_train.flatten()\n",
        "y_test_true = y_test.flatten()\n",
        "\n",
        "# evaluate the model\n",
        "loss, rmse, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "#print the results\n",
        "print(\"MSE: \", loss)\n",
        "print(\"RMSE: \", rmse)\n",
        "print(\"F1 Score: \", f1_score)\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \",  recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271RL3NmcT50",
        "outputId": "ee116516-04ed-4c17-b491-5725261ed2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1345/1345 [==============================] - 3s 2ms/step\n",
            "337/337 [==============================] - 1s 2ms/step\n",
            "MSE:  0.07643666863441467\n",
            "RMSE:  0.2764718234539032\n",
            "F1 Score:  0.9237759709358215\n",
            "Precision:  0.9235633015632629\n",
            "Recall:  0.9235633015632629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN FOR NOW\n",
        "#Todo: Update the plot to show calculated metrics\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history['accuracy'], '*-')\n",
        "plt.plot(history['val_accuracy'], '*-')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history['loss'], '*-')\n",
        "plt.plot(history['val_loss'], '*-')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "mjb_EkCzJBVi",
        "outputId": "8bc09224-a444-4b44-8af3-5595eb079aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2277f06bcab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load infected dataset\n",
        "ratings_infected = pd.read_csv('sample_data/amazon_50k_bandwagon.csv')\n",
        "empty_cols = [col for col in ratings_infected.columns if ratings_infected[col].isnull().all()]\n",
        "\n",
        "if len(empty_cols) > 0:\n",
        "    # Remove the empty column\n",
        "    ratings_infected = ratings_infected.drop(columns=empty_cols)\n",
        "\n",
        "ratings_infected.columns = ['userId', 'itemId', 'rating']\n",
        "print(ratings_infected)\n",
        "\n",
        "\n",
        "\n",
        "mean_infected = np.mean(ratings_infected['rating'])\n",
        "std_infected = np.std(ratings_infected['rating'])\n",
        "ratings_infected['z-score'] = (ratings_infected['rating'] - mean_infected)/std_infected\n",
        "\n",
        "threshold = 2.0\n",
        "ratings_infected['sus'] = np.where(ratings_infected['z-score'].abs() > threshold, 1, 0)\n",
        "print(ratings_infected)\n",
        "\n",
        "user_encoder_i = preprocessing.LabelEncoder()\n",
        "user_encoder_i.fit(ratings_infected['userId'])\n",
        "item_encoder_i = preprocessing.LabelEncoder()\n",
        "ratings_infected['userId'] = user_encoder_i.transform(ratings_infected['userId'])\n",
        "ratings_infected['itemId'] = item_encoder_i.fit_transform(ratings_infected['itemId'])\n",
        "print('------------------encoded user and item IDs---------------------')\n",
        "print(ratings_infected)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_infected, test_infected = train_test_split(ratings_infected, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the training and testing sets into arrays\n",
        "X_train_infected = np.array(train_infected['userId'])\n",
        "y_train_infected = np.array(train_infected['sus'])\n",
        "X_test_infected = np.array(test_infected['userId'])\n",
        "y_test_infected = np.array(test_infected['sus'])\n",
        "\n",
        "# Compute the number of unique user IDs in the dataset\n",
        "num_users_infected = ratings_infected['userId'].nunique()\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train_infected = to_categorical(y_train_infected)\n",
        "y_test_infected = to_categorical(y_test_infected)\n",
        "\n",
        "# Reshape the input data to be a 3D tensor with shape (samples, time steps, features)\n",
        "X_train_infected = np.reshape(X_train_infected, (X_train_infected.shape[0], 1, 1))\n",
        "X_test_infected = np.reshape(X_test_infected, (X_test_infected.shape[0], 1, 1))\n",
        "\n",
        "#Make predictions on the train and test sets\n",
        "y_train_pred_i = model.predict(X_train_infected)\n",
        "y_train_pred_i = (y_train_pred_i > 0.5).astype(int)\n",
        "y_test_pred_i = model.predict(X_test_infected)\n",
        "y_test_pred_i = (y_test_pred_i > 0.5).astype(int)\n",
        "\n",
        "# evaluate the model\n",
        "loss_i, rmse_i, f1_score_i, precision_i, recall_i = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "#print the results\n",
        "print(\"MSE: \", loss_i)\n",
        "print(\"RMSE: \", rmse_i)\n",
        "print(\"F1 Score: \", f1_score_i)\n",
        "print(\"Precision: \", precision_i)\n",
        "print(\"Recall: \",  recall_i)"
      ],
      "metadata": {
        "id": "ZnlD-DyKnZYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dccaa41-297d-4b6e-ba7e-6e7fda9b909b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               userId      itemId  rating\n",
            "0      A3C4IQ321NXOYM  B0009GVYNW       5\n",
            "1      A2L9O4TZT4IJG6  B0000CFPK8       5\n",
            "2      A3QEWQ4XHNY6U0  B000GX34AE       1\n",
            "3       AJWGJBKAPT1B4  B000FNKV2Y       5\n",
            "4      A25ZR0LKZPUYIH  B000AST3AK       4\n",
            "...               ...         ...     ...\n",
            "62300           52058  B000OSLUMK       4\n",
            "62301           52058  B0001ZLVCK       4\n",
            "62302           52058  B000HEDV5A       4\n",
            "62303           52058  B0009JLRNG       4\n",
            "62304           52058  B0002D000K       4\n",
            "\n",
            "[62305 rows x 3 columns]\n",
            "               userId      itemId  rating   z-score  sus\n",
            "0      A3C4IQ321NXOYM  B0009GVYNW       5  0.672579    0\n",
            "1      A2L9O4TZT4IJG6  B0000CFPK8       5  0.672579    0\n",
            "2      A3QEWQ4XHNY6U0  B000GX34AE       1 -2.672466    1\n",
            "3       AJWGJBKAPT1B4  B000FNKV2Y       5  0.672579    0\n",
            "4      A25ZR0LKZPUYIH  B000AST3AK       4 -0.163682    0\n",
            "...               ...         ...     ...       ...  ...\n",
            "62300           52058  B000OSLUMK       4 -0.163682    0\n",
            "62301           52058  B0001ZLVCK       4 -0.163682    0\n",
            "62302           52058  B000HEDV5A       4 -0.163682    0\n",
            "62303           52058  B0009JLRNG       4 -0.163682    0\n",
            "62304           52058  B0002D000K       4 -0.163682    0\n",
            "\n",
            "[62305 rows x 5 columns]\n",
            "------------------encoded user and item IDs---------------------\n",
            "       userId  itemId  rating   z-score  sus\n",
            "0       32581     120       5  0.672579    0\n",
            "1       22405      33       5  0.672579    0\n",
            "2       38023     253       1 -2.672466    1\n",
            "3       46273     232       5  0.672579    0\n",
            "4       16528     158       4 -0.163682    0\n",
            "...       ...     ...     ...       ...  ...\n",
            "62300     123     378       4 -0.163682    0\n",
            "62301     123      45       4 -0.163682    0\n",
            "62302     123     263       4 -0.163682    0\n",
            "62303     123     144       4 -0.163682    0\n",
            "62304     123      51       4 -0.163682    0\n",
            "\n",
            "[62305 rows x 5 columns]\n",
            "1558/1558 [==============================] - 3s 2ms/step\n",
            "390/390 [==============================] - 1s 3ms/step\n",
            "MSE:  0.07643666863441467\n",
            "RMSE:  0.2764718234539032\n",
            "F1 Score:  0.9237759709358215\n",
            "Precision:  0.9235633015632629\n",
            "Recall:  0.9235633015632629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "RQq1WgSyl9pa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}