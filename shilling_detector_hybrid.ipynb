{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHfTyAjN2XAn",
        "outputId": "61194fa1-3cc2-4a02-c289-503b432711de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.7)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#Set-up code\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install sklearn\n",
        "!pip install openpyxl\n",
        "!pip install numpy\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvnPk6YJwFwK"
      },
      "outputs": [],
      "source": [
        "from pandas.core.arrays import categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Embedding, LSTM, Reshape\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.metrics import Precision, Recall, BinaryAccuracy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from scipy.stats import zscore\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPjsgYL0w0bG",
        "outputId": "07a139c2-b932-46dc-e61f-1e40e3bbb317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       userId  itemId  rating\n",
            "0         186     302       3\n",
            "1          22     377       1\n",
            "2         244      51       2\n",
            "3         166     346       1\n",
            "4         298     474       4\n",
            "...       ...     ...     ...\n",
            "99994     880     476       3\n",
            "99995     716     204       5\n",
            "99996     276    1090       1\n",
            "99997      13     225       2\n",
            "99998      12     203       3\n",
            "\n",
            "[99999 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "ratings = pd.read_csv('sample_data/ml_100k.csv')\n",
        "empty_cols = [col for col in ratings.columns if ratings[col].isnull().all()]\n",
        "\n",
        "if len(empty_cols) > 0:\n",
        "    # Remove the empty column\n",
        "    ratings = ratings.drop(columns=empty_cols)\n",
        "\n",
        "ratings.columns = ['userId', 'itemId', 'rating']\n",
        "print(ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuzVEb0RyG0z"
      },
      "outputs": [],
      "source": [
        "# Create a binary column indicating whether a rating is suspicious (1) or not (0)\n",
        "#ratings['suspicious'] = np.where(ratings['rating'] >= 4, 0, 1)\n",
        "#print(ratings)\n",
        "\n",
        "mean = np.mean(ratings['rating'])\n",
        "std = np.std(ratings['rating'])\n",
        "ratings['z-score'] = (ratings['rating'] - mean)/std\n",
        "\n",
        "threshold = 2.0\n",
        "ratings['sus'] = np.where(ratings['z-score'].abs() > threshold, 1, 0)\n",
        "\n",
        "\n",
        "\n",
        "user_encoder = preprocessing.LabelEncoder()\n",
        "user_encoder.fit(ratings['userId'])\n",
        "item_encoder = preprocessing.LabelEncoder()\n",
        "ratings['userId'] = user_encoder.transform(ratings['userId'])\n",
        "ratings['itemId'] = item_encoder.fit_transform(ratings['itemId'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ-jorNrzaqW"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into input features and labels\n",
        "X = ratings[['userId', 'itemId', 'rating']].values\n",
        "y = ratings['sus'].values\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the input features for the LSTM model\n",
        "timesteps = 1\n",
        "input_dim = 3\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_dim))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, input_dim))\n",
        "\n",
        "# Convert the labels to categorical format\n",
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC9Smksu0GFg"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(1, 3)))\n",
        "model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Reshape for LSTM\n",
        "model.add(Reshape((1, -1))) # -1 to infer the number of features\n",
        "\n",
        "\n",
        "# output_size = 1\n",
        "# Add LSTM layers\n",
        "# Add LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32, activation=\"sigmoid\", return_sequences=True))\n",
        "\n",
        "# Reshape the output of the second LSTM layer\n",
        "model.add(Reshape((-1, 32)))\n",
        "\n",
        "# Add BatchNormalization and Dropout layers\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Add a fully connected layer with sigmoid activation\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "model.add(Reshape((-1, 32)))\n",
        "model.add(Dense(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulzNFwaO0LxN",
        "outputId": "60285211-7d2e-474a-9dbf-d31e5720e99f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - 5s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "MAE:  0.060850005596876144\n",
            "RMSE:  0.2466779202222824\n",
            "F1 Score:  0.9391499757766724\n",
            "Precision:  0.9391499757766724\n",
            "Recall:  0.9391499757766724\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#assuming X and y are defined\n",
        "y = y[:99999]\n",
        "\n",
        "X = X.reshape(X.shape[0], 1, 3)\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, min_delta = 0.01)\n",
        "\n",
        "#compile model\n",
        "#avoid exploding/vanishing gradient problem by setting clipoff\n",
        "\n",
        "#Compiling the model with the Precision, Recall, and F1 score metrics does not work \n",
        "\n",
        "\n",
        "#WORKING BUT ONLY RMSE AND MAE\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['RootMeanSquaredError', 'MeanAbsoluteError'])\n",
        "\n",
        "\n",
        "\n",
        " # fit model\n",
        "model.fit(\n",
        "      X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32,callbacks=[callback]\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Evaluate the Model\n",
        "#WORKING FOR RMSE AND MAE\n",
        "model.summary()\n",
        "results = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('RMSE:',results[1],'\\n','MAE:',results[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# converting the nested arrays into a list\n",
        "y_pred_merged = np.concatenate(y_pred_binary)\n",
        "list_y_pred_merged = y_pred_merged.tolist()\n",
        "list_merged = []\n",
        "for arr in list_y_pred_merged:\n",
        "    for elem in arr:\n",
        "        list_merged.append(elem)\n",
        "print(list_merged)\n",
        "y_pred_binary1= list_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test= y_test.tolist()\n",
        "y_test1 = [x[0] for x in y_test]\n",
        "\n",
        "print(y_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(X_test),len( y_pred_binary1),len(y_test1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision = precision_score(y_test1, y_pred_binary1)\n",
        "recall = recall_score(y_test1, y_pred_binary1)\n",
        "f1 = f1_score(y_test1, y_pred_binary1, average='weighted', labels=np.unique(y_pred_binary1))\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVkrQETD41pZ",
        "outputId": "ac7e2961-576a-43fd-c1b5-367494c97a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        userId  itemId  rating\n",
            "0          344     216       4\n",
            "1          344     215       3\n",
            "2          344     213       4\n",
            "3          344     210       4\n",
            "4          344     762       3\n",
            "...        ...     ...     ...\n",
            "109921    1059     195       4\n",
            "109922    1059     541       4\n",
            "109923    1059     807       4\n",
            "109924    1059     153       4\n",
            "109925    1059     804       4\n",
            "\n",
            "[109926 rows x 3 columns]\n",
            "        userId  itemId  rating   z-score  sus\n",
            "0          344     216       4  0.404923    0\n",
            "1          344     215       3 -0.505427    0\n",
            "2          344     213       4  0.404923    0\n",
            "3          344     210       4  0.404923    0\n",
            "4          344     762       3 -0.505427    0\n",
            "...        ...     ...     ...       ...  ...\n",
            "109921    1059     195       4  0.404923    0\n",
            "109922    1059     541       4  0.404923    0\n",
            "109923    1059     807       4  0.404923    0\n",
            "109924    1059     153       4  0.404923    0\n",
            "109925    1059     804       4  0.404923    0\n",
            "\n",
            "[109926 rows x 5 columns]\n",
            "------------------encoded user and item IDs---------------------\n",
            "        userId  itemId  rating   z-score  sus\n",
            "0          343     215       4  0.404923    0\n",
            "1          343     214       3 -0.505427    0\n",
            "2          343     212       4  0.404923    0\n",
            "3          343     209       4  0.404923    0\n",
            "4          343     761       3 -0.505427    0\n",
            "...        ...     ...     ...       ...  ...\n",
            "109921    1058     194       4  0.404923    0\n",
            "109922    1058     540       4  0.404923    0\n",
            "109923    1058     806       4  0.404923    0\n",
            "109924    1058     152       4  0.404923    0\n",
            "109925    1058     803       4  0.404923    0\n",
            "\n",
            "[109926 rows x 5 columns]\n",
            "2500/2500 [==============================] - 7s 3ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "MAE:  0.060850005596876144\n",
            "RMSE:  0.2466779202222824\n",
            "F1 Score:  0.9391499757766724\n",
            "Precision:  0.9391499757766724\n",
            "Recall:  0.9391499757766724\n"
          ]
        }
      ],
      "source": [
        "#load infected dataset\n",
        "ratings_infected = pd.read_csv('sample_data/amazon_50k_bandwagon.csv')\n",
        "empty_cols = [col for col in ratings_infected.columns if ratings_infected[col].isnull().all()]\n",
        "\n",
        "if len(empty_cols) > 0:\n",
        "    # Remove the empty column\n",
        "    ratings_infected = ratings_infected.drop(columns=empty_cols)\n",
        "\n",
        "ratings_infected.columns = ['userId', 'itemId', 'rating']\n",
        "print(ratings_infected)\n",
        "\n",
        "\n",
        "\n",
        "mean_infected = np.mean(ratings_infected['rating'])\n",
        "std_infected = np.std(ratings_infected['rating'])\n",
        "ratings_infected['z-score'] = (ratings_infected['rating'] - mean_infected)/std_infected\n",
        "\n",
        "threshold = 2.0\n",
        "ratings_infected['sus'] = np.where(ratings_infected['z-score'].abs() > threshold, 1, 0)\n",
        "print(ratings_infected)\n",
        "\n",
        "user_encoder_i = preprocessing.LabelEncoder()\n",
        "user_encoder_i.fit(ratings_infected['userId'])\n",
        "item_encoder_i = preprocessing.LabelEncoder()\n",
        "ratings_infected['userId'] = user_encoder_i.transform(ratings_infected['userId'])\n",
        "ratings_infected['itemId'] = item_encoder_i.fit_transform(ratings_infected['itemId'])\n",
        "print('------------------encoded user and item IDs---------------------')\n",
        "print(ratings_infected)\n",
        "\n",
        "# Split the dataset into input features and labels\n",
        "Xi = ratings[['userId', 'itemId', 'rating']].values\n",
        "yi = ratings['sus'].values\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train_infected, X_test_infected, y_train_infected, y_test_infected = train_test_split(Xi, yi, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train_infected = scaler.fit_transform(X_train_infected)\n",
        "X_test_infected = scaler.transform(X_test_infected)\n",
        "\n",
        "# Reshape the input features for the LSTM model\n",
        "timesteps = 1\n",
        "input_dim = 3\n",
        "X_train_infected = np.reshape(X_train_infected, (X_train_infected.shape[0], timesteps, input_dim))\n",
        "X_test_infected = np.reshape(X_test_infected, (X_test_infected.shape[0], timesteps, input_dim))\n",
        "\n",
        "# Convert the labels to categorical format\n",
        "num_classes = 2\n",
        "y_train_infected = keras.utils.to_categorical(y_train_infected, num_classes)\n",
        "y_test_infected = keras.utils.to_categorical(y_test_infected, num_classes)\n",
        "\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "resultsi = model.evaluate(X_test_infected, y_test_infected, batch_size=100)\n",
        "print('RMSE:',resultsi[1],'\\n','MAE:',resultsi[2])\n",
        "\n",
        "# Calculate predictions\n",
        "y_pred_infected = model.predict(X_test_infected)\n",
        "\n",
        "# Convert predictions to binary format\n",
        "y_pred_infected = (y_pred_infected > 0.5).astype(int)\n",
        "\n",
        "# converting the nested arrays into a list\n",
        "y_pred_i_merged = np.concatenate(y_pred_infected)\n",
        "list_y_pred_i_merged = y_pred_i_merged.tolist()\n",
        "list_i_merged = []\n",
        "for arr in list_y_pred_i_merged:\n",
        "    for elem in arr:\n",
        "        list_i_merged.append(elem)\n",
        "print(list_i_merged)\n",
        "y_pred_i_binary1= list_i_merged\n",
        "\n",
        "y_test_infected= y_test_infected.tolist()\n",
        "y_test_infected1 = [x[0] for x in y_test_infected]\n",
        "\n",
        "print(y_test_infected1)\n",
        "\n",
        "precision_i = precision_score(y_test_infected1, y_pred_i_binary1)\n",
        "recall_i = recall_score(y_test_infected1, y_pred_i_binary1)\n",
        "f1_i = f1_score(y_test_infected1, y_pred_i_binary1)\n",
        "\n",
        "print(\"Precision:\", precision_i)\n",
        "print(\"Recall:\", recall_i)\n",
        "print(\"F1 Score:\", f1_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guuWyNjb42X5"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.reset_default_graph()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
